{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "882 99\n",
      "882 99\n",
      "==> Building model..\n",
      "\n",
      "Epoch: 0\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 1.886 | Acc: 24.000% (212/882)        7/7 \n",
      "mainpro_CK+_mobilenetv2.py:149: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
      " [============================>.] | Loss: 1.879 | Acc: 21.000% (21/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 21.000\n",
      "\n",
      "Epoch: 1\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 1.835 | Acc: 27.000% (242/882)        7/7 \n",
      " [============================>.] | Loss: 1.874 | Acc: 21.000% (21/99)          20/20 \n",
      "\n",
      "Epoch: 2\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 1.799 | Acc: 30.000% (270/882)        7/7 \n",
      " [============================>.] | Loss: 1.907 | Acc: 12.000% (12/99)          20/20 \n",
      "\n",
      "Epoch: 3\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 1.709 | Acc: 36.000% (319/882)        7/7 \n",
      " [============================>.] | Loss: 1.893 | Acc: 18.000% (18/99)          20/20 \n",
      "\n",
      "Epoch: 4\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 1.481 | Acc: 44.000% (393/882)        7/7 \n",
      " [============================>.] | Loss: 1.886 | Acc: 24.000% (24/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 24.000\n",
      "\n",
      "Epoch: 5\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 1.334 | Acc: 48.000% (429/882)        7/7 \n",
      " [============================>.] | Loss: 1.984 | Acc: 21.000% (21/99)          20/20 \n",
      "\n",
      "Epoch: 6\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 1.210 | Acc: 53.000% (475/882)        7/7 \n",
      " [============================>.] | Loss: 1.966 | Acc: 18.000% (18/99)          20/20 \n",
      "\n",
      "Epoch: 7\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 1.046 | Acc: 59.000% (528/882)        7/7 \n",
      " [============================>.] | Loss: 1.984 | Acc: 21.000% (21/99)          20/20 \n",
      "\n",
      "Epoch: 8\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.921 | Acc: 66.000% (586/882)        7/7 \n",
      " [============================>.] | Loss: 1.881 | Acc: 34.000% (34/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 34.000\n",
      "\n",
      "Epoch: 9\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.781 | Acc: 70.000% (620/882)        7/7 \n",
      " [============================>.] | Loss: 1.809 | Acc: 28.000% (28/99)          20/20 \n",
      "\n",
      "Epoch: 10\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.726 | Acc: 74.000% (659/882)        7/7 \n",
      " [============================>.] | Loss: 1.808 | Acc: 39.000% (39/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 39.000\n",
      "\n",
      "Epoch: 11\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.495 | Acc: 81.000% (723/882)        7/7 \n",
      " [============================>.] | Loss: 1.692 | Acc: 44.000% (44/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 44.000\n",
      "\n",
      "Epoch: 12\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.401 | Acc: 85.000% (754/882)        7/7 \n",
      " [============================>.] | Loss: 1.814 | Acc: 40.000% (40/99)          20/20 \n",
      "\n",
      "Epoch: 13\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.327 | Acc: 89.000% (793/882)        7/7 \n",
      " [============================>.] | Loss: 2.207 | Acc: 42.000% (42/99)          20/20 \n",
      "\n",
      "Epoch: 14\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.380 | Acc: 87.000% (771/882)        7/7 \n",
      " [============================>.] | Loss: 1.529 | Acc: 52.000% (52/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 52.000\n",
      "\n",
      "Epoch: 15\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.290 | Acc: 89.000% (785/882)        7/7 \n",
      " [============================>.] | Loss: 0.890 | Acc: 66.000% (66/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 66.000\n",
      "\n",
      "Epoch: 16\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.226 | Acc: 92.000% (814/882)        7/7 \n",
      " [============================>.] | Loss: 1.531 | Acc: 60.000% (60/99)          20/20 \n",
      "\n",
      "Epoch: 17\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.182 | Acc: 93.000% (827/882)        7/7 \n",
      " [============================>.] | Loss: 1.093 | Acc: 68.000% (68/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 68.000\n",
      "\n",
      "Epoch: 18\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.158 | Acc: 94.000% (835/882)        7/7 \n",
      " [============================>.] | Loss: 0.811 | Acc: 74.000% (74/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 74.000\n",
      "\n",
      "Epoch: 19\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.173 | Acc: 93.000% (827/882)        7/7 \n",
      " [============================>.] | Loss: 1.145 | Acc: 63.000% (63/99)          20/20 \n",
      "\n",
      "Epoch: 20\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.134 | Acc: 95.000% (839/882)        7/7 \n",
      " [============================>.] | Loss: 0.892 | Acc: 80.000% (80/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 80.000\n",
      "\n",
      "Epoch: 21\n",
      "learning_rate: 0.008\n",
      " [=========================>....] | Loss: 0.112 | Acc: 96.000% (848/882)        7/7 \n",
      " [============================>.] | Loss: 0.842 | Acc: 76.000% (76/99)          20/20 \n",
      "\n",
      "Epoch: 22\n",
      "learning_rate: 0.006400000000000001\n",
      " [=========================>....] | Loss: 0.087 | Acc: 96.000% (855/882)        7/7 \n",
      " [============================>.] | Loss: 0.841 | Acc: 76.000% (76/99)          20/20 \n",
      "\n",
      "Epoch: 23\n",
      "learning_rate: 0.005120000000000001\n",
      " [=========================>....] | Loss: 0.063 | Acc: 97.000% (864/882)        7/7 \n",
      " [============================>.] | Loss: 0.848 | Acc: 75.000% (75/99)          20/20 \n",
      "\n",
      "Epoch: 24\n",
      "learning_rate: 0.004096000000000001\n",
      " [=========================>....] | Loss: 0.039 | Acc: 98.000% (873/882)        7/7 \n",
      " [============================>.] | Loss: 0.836 | Acc: 73.000% (73/99)          20/20 \n",
      "\n",
      "Epoch: 25\n",
      "learning_rate: 0.0032768000000000007\n",
      " [=========================>....] | Loss: 0.021 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.817 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 26\n",
      "learning_rate: 0.002621440000000001\n",
      " [=========================>....] | Loss: 0.012 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.833 | Acc: 69.000% (69/99)          20/20 \n",
      "\n",
      "Epoch: 27\n",
      "learning_rate: 0.002097152000000001\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.821 | Acc: 70.000% (70/99)          20/20 \n",
      "\n",
      "Epoch: 28\n",
      "learning_rate: 0.001677721600000001\n",
      " [=========================>....] | Loss: 0.012 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.832 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 29\n",
      "learning_rate: 0.0013421772800000006\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.831 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 30\n",
      "learning_rate: 0.0010737418240000006\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.841 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 31\n",
      "learning_rate: 0.0008589934592000006\n",
      " [=========================>....] | Loss: 0.012 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.816 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 32\n",
      "learning_rate: 0.0006871947673600004\n",
      " [=========================>....] | Loss: 0.005 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.819 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 33\n",
      "learning_rate: 0.0005497558138880004\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.811 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 34\n",
      "learning_rate: 0.00043980465111040037\n",
      " [=========================>....] | Loss: 0.007 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.794 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 35\n",
      "learning_rate: 0.0003518437208883203\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.801 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 36\n",
      "learning_rate: 0.00028147497671065624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.801 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 37\n",
      "learning_rate: 0.00022517998136852504\n",
      " [=========================>....] | Loss: 0.005 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.804 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 38\n",
      "learning_rate: 0.00018014398509482002\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.804 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 39\n",
      "learning_rate: 0.00014411518807585602\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.798 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 40\n",
      "learning_rate: 0.00011529215046068484\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.797 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 41\n",
      "learning_rate: 9.223372036854788e-05\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.790 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 42\n",
      "learning_rate: 7.37869762948383e-05\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.797 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 43\n",
      "learning_rate: 5.902958103587064e-05\n",
      " [=========================>....] | Loss: 0.007 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.801 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 44\n",
      "learning_rate: 4.722366482869652e-05\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.801 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 45\n",
      "learning_rate: 3.777893186295722e-05\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.796 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 46\n",
      "learning_rate: 3.0223145490365776e-05\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.807 | Acc: 70.000% (70/99)          20/20 \n",
      "\n",
      "Epoch: 47\n",
      "learning_rate: 2.417851639229262e-05\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.803 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 48\n",
      "learning_rate: 1.9342813113834096e-05\n",
      " [=========================>....] | Loss: 0.005 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.795 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 49\n",
      "learning_rate: 1.547425049106728e-05\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.802 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 50\n",
      "learning_rate: 1.2379400392853824e-05\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.798 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 51\n",
      "learning_rate: 9.903520314283058e-06\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.812 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 52\n",
      "learning_rate: 7.922816251426448e-06\n",
      " [=========================>....] | Loss: 0.007 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.807 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 53\n",
      "learning_rate: 6.338253001141158e-06\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.807 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 54\n",
      "learning_rate: 5.0706024009129275e-06\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.807 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 55\n",
      "learning_rate: 4.056481920730342e-06\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.813 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 56\n",
      "learning_rate: 3.2451855365842735e-06\n",
      " [=========================>....] | Loss: 0.005 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.808 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 57\n",
      "learning_rate: 2.5961484292674196e-06\n",
      " [=========================>....] | Loss: 0.006 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.816 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 58\n",
      "learning_rate: 2.0769187434139356e-06\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.817 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 59\n",
      "learning_rate: 1.6615349947311485e-06\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.810 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 60\n",
      "learning_rate: 1.3292279957849189e-06\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.805 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 61\n",
      "learning_rate: 1.0633823966279351e-06\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.801 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 62\n",
      "learning_rate: 8.507059173023481e-07\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.812 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 63\n",
      "learning_rate: 6.805647338418786e-07\n",
      " [=========================>....] | Loss: 0.006 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.811 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 64\n",
      "learning_rate: 5.444517870735029e-07\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.804 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 65\n",
      "learning_rate: 4.3556142965880233e-07\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.791 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 66\n",
      "learning_rate: 3.484491437270419e-07\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.797 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 67\n",
      "learning_rate: 2.787593149816335e-07\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.806 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 68\n",
      "learning_rate: 2.2300745198530684e-07\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.805 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 69\n",
      "learning_rate: 1.784059615882455e-07\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.799 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 70\n",
      "learning_rate: 1.4272476927059639e-07\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.794 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 71\n",
      "learning_rate: 1.1417981541647711e-07\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.803 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 72\n",
      "learning_rate: 9.13438523331817e-08\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.800 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 73\n",
      "learning_rate: 7.307508186654536e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.806 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 74\n",
      "learning_rate: 5.846006549323629e-08\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.801 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 75\n",
      "learning_rate: 4.676805239458904e-08\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.803 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 76\n",
      "learning_rate: 3.741444191567123e-08\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.801 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 77\n",
      "learning_rate: 2.9931553532536985e-08\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.791 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 78\n",
      "learning_rate: 2.3945242826029592e-08\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.810 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 79\n",
      "learning_rate: 1.9156194260823674e-08\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.813 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 80\n",
      "learning_rate: 1.532495540865894e-08\n",
      " [=========================>....] | Loss: 0.014 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.798 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 81\n",
      "learning_rate: 1.2259964326927151e-08\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.805 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 82\n",
      "learning_rate: 9.807971461541723e-09\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.798 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 83\n",
      "learning_rate: 7.846377169233378e-09\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.799 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 84\n",
      "learning_rate: 6.277101735386703e-09\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.809 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 85\n",
      "learning_rate: 5.0216813883093625e-09\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.811 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 86\n",
      "learning_rate: 4.017345110647491e-09\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.809 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 87\n",
      "learning_rate: 3.2138760885179924e-09\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.793 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 88\n",
      "learning_rate: 2.5711008708143944e-09\n",
      " [=========================>....] | Loss: 0.006 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.798 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 89\n",
      "learning_rate: 2.0568806966515157e-09\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.802 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 90\n",
      "learning_rate: 1.6455045573212124e-09\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.805 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 91\n",
      "learning_rate: 1.31640364585697e-09\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.797 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 92\n",
      "learning_rate: 1.0531229166855762e-09\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.791 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 93\n",
      "learning_rate: 8.42498333348461e-10\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.802 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 94\n",
      "learning_rate: 6.739986666787687e-10\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.805 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 95\n",
      "learning_rate: 5.39198933343015e-10\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.803 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 96\n",
      "learning_rate: 4.3135914667441205e-10\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.801 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 97\n",
      "learning_rate: 3.450873173395297e-10\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.792 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 98\n",
      "learning_rate: 2.7606985387162373e-10\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.790 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 99\n",
      "learning_rate: 2.2085588309729901e-10\n",
      " [=========================>....] | Loss: 0.008 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.811 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 100\n",
      "learning_rate: 1.7668470647783923e-10\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.809 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 101\n",
      "learning_rate: 1.413477651822714e-10\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.806 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 102\n",
      "learning_rate: 1.130782121458171e-10\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.808 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 103\n",
      "learning_rate: 9.04625697166537e-11\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.806 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 104\n",
      "learning_rate: 7.237005577332295e-11\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.804 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 105\n",
      "learning_rate: 5.789604461865837e-11\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.794 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 106\n",
      "learning_rate: 4.63168356949267e-11\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.799 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 107\n",
      "learning_rate: 3.7053468555941365e-11\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.800 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 108\n",
      "learning_rate: 2.964277484475309e-11\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.802 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 109\n",
      "learning_rate: 2.3714219875802474e-11\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.803 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 110\n",
      "learning_rate: 1.8971375900641982e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.794 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 111\n",
      "learning_rate: 1.5177100720513584e-11\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.808 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 112\n",
      "learning_rate: 1.2141680576410869e-11\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.803 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 113\n",
      "learning_rate: 9.713344461128697e-12\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.794 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 114\n",
      "learning_rate: 7.770675568902958e-12\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.796 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 115\n",
      "learning_rate: 6.216540455122366e-12\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.797 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 116\n",
      "learning_rate: 4.973232364097893e-12\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.814 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 117\n",
      "learning_rate: 3.978585891278314e-12\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.808 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 118\n",
      "learning_rate: 3.182868713022652e-12\n",
      " [=========================>....] | Loss: 0.006 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.822 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 119\n",
      "learning_rate: 2.5462949704181215e-12\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.811 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 120\n",
      "learning_rate: 2.0370359763344977e-12\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.809 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 121\n",
      "learning_rate: 1.629628781067598e-12\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.808 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 122\n",
      "learning_rate: 1.3037030248540785e-12\n",
      " [=========================>....] | Loss: 0.004 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.805 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 123\n",
      "learning_rate: 1.0429624198832629e-12\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.799 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 124\n",
      "learning_rate: 8.343699359066104e-13\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.798 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 125\n",
      "learning_rate: 6.674959487252882e-13\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.795 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 126\n",
      "learning_rate: 5.339967589802307e-13\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.800 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 127\n",
      "learning_rate: 4.2719740718418454e-13\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.808 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 128\n",
      "learning_rate: 3.4175792574734765e-13\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.805 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 129\n",
      "learning_rate: 2.7340634059787813e-13\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.809 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 130\n",
      "learning_rate: 2.1872507247830254e-13\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.808 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 131\n",
      "learning_rate: 1.7498005798264204e-13\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.809 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 132\n",
      "learning_rate: 1.3998404638611363e-13\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.793 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 133\n",
      "learning_rate: 1.1198723710889092e-13\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.794 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 134\n",
      "learning_rate: 8.958978968711274e-14\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.801 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 135\n",
      "learning_rate: 7.167183174969019e-14\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.800 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 136\n",
      "learning_rate: 5.733746539975217e-14\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.803 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 137\n",
      "learning_rate: 4.5869972319801734e-14\n",
      " [=========================>....] | Loss: 0.007 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.806 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 138\n",
      "learning_rate: 3.669597785584139e-14\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.824 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 139\n",
      "learning_rate: 2.935678228467311e-14\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.807 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 140\n",
      "learning_rate: 2.3485425827738488e-14\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.808 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 141\n",
      "learning_rate: 1.878834066219079e-14\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.805 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 142\n",
      "learning_rate: 1.5030672529752636e-14\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.800 | Acc: 70.000% (70/99)          20/20 \n",
      "\n",
      "Epoch: 143\n",
      "learning_rate: 1.2024538023802108e-14\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.810 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 144\n",
      "learning_rate: 9.619630419041687e-15\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.806 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 145\n",
      "learning_rate: 7.69570433523335e-15\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.795 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 146\n",
      "learning_rate: 6.15656346818668e-15\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.803 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 147\n",
      "learning_rate: 4.925250774549344e-15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.805 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 148\n",
      "learning_rate: 3.940200619639476e-15\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.817 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 149\n",
      "learning_rate: 3.1521604957115808e-15\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.813 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 150\n",
      "learning_rate: 2.521728396569265e-15\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.808 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 151\n",
      "learning_rate: 2.017382717255412e-15\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.794 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 152\n",
      "learning_rate: 1.6139061738043298e-15\n",
      " [=========================>....] | Loss: 0.006 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.786 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 153\n",
      "learning_rate: 1.2911249390434638e-15\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.790 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 154\n",
      "learning_rate: 1.0328999512347711e-15\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.791 | Acc: 70.000% (70/99)          20/20 \n",
      "\n",
      "Epoch: 155\n",
      "learning_rate: 8.263199609878169e-16\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.794 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 156\n",
      "learning_rate: 6.610559687902537e-16\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.810 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 157\n",
      "learning_rate: 5.288447750322029e-16\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.810 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 158\n",
      "learning_rate: 4.2307582002576235e-16\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.806 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 159\n",
      "learning_rate: 3.384606560206099e-16\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.808 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 160\n",
      "learning_rate: 2.7076852481648796e-16\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.815 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 161\n",
      "learning_rate: 2.1661481985319035e-16\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.819 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 162\n",
      "learning_rate: 1.732918558825523e-16\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.824 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 163\n",
      "learning_rate: 1.3863348470604184e-16\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.814 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 164\n",
      "learning_rate: 1.1090678776483348e-16\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.814 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 165\n",
      "learning_rate: 8.87254302118668e-17\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.800 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 166\n",
      "learning_rate: 7.098034416949344e-17\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.808 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 167\n",
      "learning_rate: 5.678427533559476e-17\n",
      " [=========================>....] | Loss: 0.006 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.808 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 168\n",
      "learning_rate: 4.5427420268475807e-17\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.792 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 169\n",
      "learning_rate: 3.6341936214780644e-17\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.803 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 170\n",
      "learning_rate: 2.907354897182452e-17\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.800 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 171\n",
      "learning_rate: 2.3258839177459616e-17\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.802 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 172\n",
      "learning_rate: 1.8607071341967693e-17\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.799 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 173\n",
      "learning_rate: 1.4885657073574156e-17\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.792 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 174\n",
      "learning_rate: 1.1908525658859325e-17\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.793 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 175\n",
      "learning_rate: 9.52682052708746e-18\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.797 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 176\n",
      "learning_rate: 7.62145642166997e-18\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.811 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 177\n",
      "learning_rate: 6.0971651373359754e-18\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.801 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 178\n",
      "learning_rate: 4.877732109868781e-18\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.805 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 179\n",
      "learning_rate: 3.902185687895025e-18\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.791 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 180\n",
      "learning_rate: 3.12174855031602e-18\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.795 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 181\n",
      "learning_rate: 2.497398840252816e-18\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.798 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 182\n",
      "learning_rate: 1.997919072202253e-18\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.797 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 183\n",
      "learning_rate: 1.5983352577618025e-18\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.804 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 184\n",
      "learning_rate: 1.278668206209442e-18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.799 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 185\n",
      "learning_rate: 1.0229345649675538e-18\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.792 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 186\n",
      "learning_rate: 8.18347651974043e-19\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.794 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 187\n",
      "learning_rate: 6.546781215792345e-19\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.800 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 188\n",
      "learning_rate: 5.237424972633876e-19\n",
      " [=========================>....] | Loss: 0.006 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.790 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 189\n",
      "learning_rate: 4.189939978107101e-19\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.809 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 190\n",
      "learning_rate: 3.3519519824856807e-19\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.800 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 191\n",
      "learning_rate: 2.681561585988545e-19\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.799 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 192\n",
      "learning_rate: 2.145249268790836e-19\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.781 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 193\n",
      "learning_rate: 1.7161994150326688e-19\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.793 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 194\n",
      "learning_rate: 1.3729595320261352e-19\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.811 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 195\n",
      "learning_rate: 1.098367625620908e-19\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.797 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 196\n",
      "learning_rate: 8.786941004967267e-20\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.797 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 197\n",
      "learning_rate: 7.029552803973813e-20\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.807 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 198\n",
      "learning_rate: 5.623642243179051e-20\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.811 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 199\n",
      "learning_rate: 4.498913794543241e-20\n",
      " [=========================>....] | Loss: 0.006 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.793 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 200\n",
      "learning_rate: 3.5991310356345934e-20\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.801 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 201\n",
      "learning_rate: 2.8793048285076746e-20\n",
      " [=========================>....] | Loss: 0.009 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.803 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 202\n",
      "learning_rate: 2.30344386280614e-20\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.804 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 203\n",
      "learning_rate: 1.8427550902449122e-20\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.788 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 204\n",
      "learning_rate: 1.4742040721959298e-20\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.801 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 205\n",
      "learning_rate: 1.1793632577567439e-20\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.818 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 206\n",
      "learning_rate: 9.43490606205395e-21\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.808 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 207\n",
      "learning_rate: 7.547924849643161e-21\n",
      " [=========================>....] | Loss: 0.007 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.796 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 208\n",
      "learning_rate: 6.0383398797145295e-21\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.804 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 209\n",
      "learning_rate: 4.8306719037716234e-21\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.801 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 210\n",
      "learning_rate: 3.864537523017299e-21\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.792 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 211\n",
      "learning_rate: 3.0916300184138396e-21\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.805 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 212\n",
      "learning_rate: 2.4733040147310717e-21\n",
      " [=========================>....] | Loss: 0.005 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.815 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 213\n",
      "learning_rate: 1.9786432117848575e-21\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.822 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 214\n",
      "learning_rate: 1.5829145694278862e-21\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.810 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 215\n",
      "learning_rate: 1.266331655542309e-21\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.815 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 216\n",
      "learning_rate: 1.0130653244338472e-21\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.808 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 217\n",
      "learning_rate: 8.104522595470779e-22\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.807 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 218\n",
      "learning_rate: 6.483618076376623e-22\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.807 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 219\n",
      "learning_rate: 5.186894461101298e-22\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.792 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 220\n",
      "learning_rate: 4.149515568881039e-22\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.791 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 221\n",
      "learning_rate: 3.3196124551048316e-22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.787 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 222\n",
      "learning_rate: 2.6556899640838656e-22\n",
      " [=========================>....] | Loss: 0.010 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.799 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 223\n",
      "learning_rate: 2.1245519712670924e-22\n",
      " [=========================>....] | Loss: 0.005 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.816 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 224\n",
      "learning_rate: 1.699641577013674e-22\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.813 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 225\n",
      "learning_rate: 1.3597132616109392e-22\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.805 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 226\n",
      "learning_rate: 1.0877706092887513e-22\n",
      " [=========================>....] | Loss: 0.006 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.809 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 227\n",
      "learning_rate: 8.702164874310012e-23\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.805 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 228\n",
      "learning_rate: 6.96173189944801e-23\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.789 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 229\n",
      "learning_rate: 5.569385519558409e-23\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.794 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 230\n",
      "learning_rate: 4.455508415646727e-23\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.795 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 231\n",
      "learning_rate: 3.5644067325173816e-23\n",
      " [=========================>....] | Loss: 0.015 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.809 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 232\n",
      "learning_rate: 2.851525386013906e-23\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.802 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 233\n",
      "learning_rate: 2.2812203088111247e-23\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.796 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 234\n",
      "learning_rate: 1.8249762470489e-23\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.799 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 235\n",
      "learning_rate: 1.45998099763912e-23\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.814 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 236\n",
      "learning_rate: 1.167984798111296e-23\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.809 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 237\n",
      "learning_rate: 9.343878384890368e-24\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.794 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 238\n",
      "learning_rate: 7.475102707912296e-24\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.800 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 239\n",
      "learning_rate: 5.9800821663298366e-24\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.808 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 240\n",
      "learning_rate: 4.784065733063869e-24\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.799 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 241\n",
      "learning_rate: 3.827252586451096e-24\n",
      " [=========================>....] | Loss: 0.005 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.805 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 242\n",
      "learning_rate: 3.061802069160877e-24\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.813 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 243\n",
      "learning_rate: 2.4494416553287016e-24\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.813 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 244\n",
      "learning_rate: 1.9595533242629614e-24\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.806 | Acc: 71.000% (71/99)          20/20 \n",
      "\n",
      "Epoch: 245\n",
      "learning_rate: 1.5676426594103693e-24\n",
      " [=========================>....] | Loss: 0.003 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.806 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 246\n",
      "learning_rate: 1.2541141275282953e-24\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.791 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 247\n",
      "learning_rate: 1.0032913020226365e-24\n",
      " [=========================>....] | Loss: 0.005 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.796 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 248\n",
      "learning_rate: 8.026330416181091e-25\n",
      " [=========================>....] | Loss: 0.004 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.812 | Acc: 72.000% (72/99)          20/20 \n",
      "\n",
      "Epoch: 249\n",
      "learning_rate: 6.421064332944874e-25\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.807 | Acc: 72.000% (72/99)          20/20 \n",
      "best_Test_acc: 80.000\n",
      "best_Test_acc_epoch: 20\n"
     ]
    }
   ],
   "source": [
    "!python mainpro_CK+_mobilenetv2.py --model mobilenetv2 --bs 128 --lr 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "img should be PIL Image. Got <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6a7886c236f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# img = np.concatenate((img, img, img), axis=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# img = Image.fromarray(img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Angry'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Disgust'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Fear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Happy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Surprise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Neutral'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/expression_recognition/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/expression_recognition/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/expression_recognition/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \"\"\"\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'img should be PIL Image. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Got inappropriate size arg: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: img should be PIL Image. Got <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "#验证模型正确性\n",
    "\"\"\"\n",
    "visualize results for test image\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import transforms as transforms\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from models import *\n",
    "\n",
    "cut_size = 32\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(cut_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "img = io.imread('images/anger_rgb.png')\n",
    "# img = raw_img[:, :, np.newaxis]\n",
    "# img = np.concatenate((img, img, img), axis=2)\n",
    "img = Image.fromarray(img)\n",
    "inputs = transform_test(img)\n",
    "\n",
    "class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "net = mobilenetv2(num_classes=7,input_size=32)\n",
    "checkpoint = torch.load(os.path.join('CK+_mobilenetv2/1/', 'Test_model.t7'))\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "net.cuda()\n",
    "net.eval()\n",
    "\n",
    "c, h, w = np.shape(inputs)\n",
    "inputs = inputs.view(-1, c, h, w)\n",
    "inputs = inputs.cuda()\n",
    "inputs = Variable(inputs, volatile=True)\n",
    "outputs = net(inputs)\n",
    "for i in range(7):\n",
    "  print('origin %10.3f' % outputs[0][i])\n",
    "\n",
    "score = F.softmax(outputs,1)\n",
    "max = score[0][0]\n",
    "maxindex = 0\n",
    "for i in range(7):\n",
    "  print('%10.3f' % score[0][i])\n",
    "  if(score[0][i] > max):\n",
    "        max = score[0][i]\n",
    "        maxindex = i\n",
    "print(\"The Expression is %s\" %str(class_names[maxindex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
